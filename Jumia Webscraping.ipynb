{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cf1a314",
   "metadata": {},
   "source": [
    "#### This project involves the scraping of phone prices from e-commerce site Jumia. Jumia is an e-commerce platform that operates in Africa. It is often referred to as the \"Amazon of Africa\" and offers a wide range of products including electronics, fashion, and household items. Jumia was founded in 2012 and is headquartered in Lagos, Nigeria. It currently operates in 14 African countries, including Egypt, Kenya, Ghana, and Morocco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d77d877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the requests, BeautifulSoup, and pandas libraries, which will be used in this project\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd \n",
    "import numpy as np \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4fdc8e",
   "metadata": {},
   "source": [
    "#### This project uses the BeautifulSoup and requests to get html elements from this website. The elements are there after imported into a pandas dataframe and stored into a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b43cee6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting page, 51\n",
      "Getting page, 52\n",
      "Getting page, 53\n",
      "Getting page, 54\n",
      "Getting page, 55\n",
      "Getting page, 56\n",
      "Getting page, 57\n",
      "Getting page, 58\n",
      "Getting page, 59\n",
      "Getting page, 60\n",
      "Getting page, 61\n",
      "Getting page, 62\n",
      "Getting page, 63\n",
      "Getting page, 64\n",
      "Getting page, 65\n",
      "Getting page, 66\n",
      "Getting page, 67\n",
      "Getting page, 68\n",
      "Getting page, 69\n",
      "Getting page, 70\n",
      "Getting page, 71\n",
      "Getting page, 72\n",
      "Getting page, 73\n",
      "Getting page, 74\n",
      "Getting page, 75\n",
      "Getting page, 76\n",
      "Getting page, 77\n",
      "Getting page, 78\n",
      "Getting page, 79\n",
      "Getting page, 80\n",
      "Getting page, 81\n",
      "Getting page, 82\n",
      "Getting page, 83\n",
      "Getting page, 84\n",
      "Getting page, 85\n",
      "Getting page, 86\n",
      "Getting page, 87\n",
      "Getting page, 88\n",
      "Getting page, 89\n",
      "Getting page, 90\n",
      "Getting page, 91\n",
      "Getting page, 92\n",
      "Getting page, 93\n",
      "Getting page, 94\n",
      "Getting page, 95\n",
      "Getting page, 96\n",
      "Getting page, 97\n",
      "Getting page, 98\n",
      "Getting page, 99\n",
      "Getting page, 100\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# The extract function basically extract the needed page of the url supplied\n",
    "def extract(page):\n",
    "\n",
    "#     Supplying the headers and url to be read by requests\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/109.0.0.0 Safari/537.36'}\n",
    "    url = f'https://www.jumia.com.ng/apple--gionee--google--huawei--infinix--itel--oppo--samsung--sony--tecno--xiaomi/?q=phone&price=50000-1000000&page={page}#catalog-listing'\n",
    "#     Getting a response from the Url\n",
    "    r = requests.get(url, headers)\n",
    "    \n",
    "#     Using BeautifulSoup library and an html.Parser to return the page in python\n",
    "    soup = BeautifulSoup(r.content, 'html.parser')\n",
    "    return soup\n",
    "    \n",
    "# The transform function retrieve the various properties of the projects. Basically supplying the needed columns to our pandas DataFrame\n",
    "def transform(soup):\n",
    "    \n",
    "#     using the find_all object to get all with class prd\n",
    "    articles = soup.find_all('article', class_=\"prd\")\n",
    "    \n",
    "#     Looping through the class to derive the individual properties\n",
    "    for item in articles:\n",
    "        name = item.find('h3', class_ = \"name\").text.strip()\n",
    "        price = item.find('div', class_ = 'prc').text.strip()\n",
    "        try:\n",
    "           link = 'https://www.jumia.com.ng' + item.find('a')['href']\n",
    "        except:\n",
    "            link = ''\n",
    "        try:\n",
    "            brand = item.find('a')['data-brand']\n",
    "        except:\n",
    "            brand = ''\n",
    "        try:\n",
    "            star = item.find('div', class_ = 'stars').text\n",
    "        except:\n",
    "            star = ''\n",
    "        try:\n",
    "            old_price = item.find('div', class_ = 'old').text\n",
    "        except:\n",
    "            old_price = ''\n",
    "        \n",
    "#         Creating a dictionary with name phones to store the obtained data\n",
    "        phones = {\n",
    "            'Brand': brand,\n",
    "            'Name': name, \n",
    "            \"Price\": price, \n",
    "            \"Old_Price\": old_price,\n",
    "            'Website': link,\n",
    "            'Star': star  \n",
    "        }\n",
    "        phonelist.append(phones)\n",
    "\n",
    "# phone_list is an empty list to append or dictionary created\n",
    "phonelist = []\n",
    "\n",
    "# Looping over 150 pages of phone searches and printing the current page, \n",
    "for i in range(51, 101, 1):\n",
    "    print(f'Getting page, {i}')\n",
    "    c = extract(i)\n",
    "    transform(c)\n",
    "    \n",
    "# Creating a pandas dataFrame and storing to a csv file named phonelist.csv    \n",
    "df = pd.DataFrame(phonelist)\n",
    "print(df.head())\n",
    "df.to_csv('phonelist3.csv')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff6b5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
